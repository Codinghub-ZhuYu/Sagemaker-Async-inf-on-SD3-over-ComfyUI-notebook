{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f343192-4cdb-468d-8048-500ac638228a",
   "metadata": {},
   "source": [
    "# Generative Fill example on Amazon SageMaker using DLC container.\n",
    "\n",
    "In this notebook, we explore how to build generative fill application and host Stable Diffusion/ ControlNet / segment anything models on SageMaker asynchronous endpoint using BYOC (Bring-your-own-container).\n",
    "\n",
    "In this notebook, under the hood we use stable-diffusion-webui and extensions to generate image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a566f-927a-4f78-baa2-f31875143781",
   "metadata": {},
   "source": [
    "Note - Amazon Web Services has no control or authority over the third-party generative AI service referenced in this Workshop, and does not make any representations or warranties that the third-party generative AI service is secure, virus-free, operational, or compatible with your production environment and standards. You are responsible for making your own independent assessment of the content provided in this Workshop, and take measures to ensure that you comply with your own specific quality control practices and standards, and the local rules, laws, regulations, licenses and terms of use that apply to you, your content, and the third-party generative AI service referenced in this Workshop. The content of this Workshop: (a) is for informational purposes only, (b) represents current Amazon Web Services product offerings and practices, which are subject to change without notice, and (c) does not create any commitments or assurances from Beijing Sinnet Technology Co., Ltd. (“Sinnet”), Ningxia Western Cloud Data Technology Co., Ltd. (“NWCD”), Amazon Connect Technology Services (Beijing) Co., Ltd. (“Amazon”), or their respective affiliates, suppliers or licensors.  Amazon Web Services’ content, products or services are provided “as is” without warranties, representations, or conditions of any kind, whether express or implied.  The responsibilities and liabilities of Sinnet, NWCD or Amazon to their respective customers are controlled by the applicable customer agreements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722516a0-6940-4860-b698-3e62f3906796",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e385cdf-8a17-4d3b-9213-d4f857907f70",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Docker image and push to ECR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3541ed7-e45e-4434-97f8-aff5b7ad9b45",
   "metadata": {},
   "source": [
    "Initialize the variables for SageMaker default bucket, role, and AWS account ID, and current AWS region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a0119c-e56a-47b7-ace1-1e76ac825c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3 \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role=\"AmazonSageMaker-ExecutionRole-20220920T203057\"\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "region_name = boto3.session.Session().region_name\n",
    "inference_image=\"sd3-compyui-notebook-7-12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7dddce-f8a4-46ad-94e0-0fe54124fb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn-north-1 415056049790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "415056049790.dkr.ecr.cn-north-1.amazonaws.com.cn/sd3-compyui-notebook-7-11:latest\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws-cn:ecr:cn-north-1:415056049790:repository/sd3-compyui-notebook-7-11\",\n",
      "            \"registryId\": \"415056049790\",\n",
      "            \"repositoryName\": \"sd3-compyui-notebook-7-11\",\n",
      "            \"repositoryUri\": \"415056049790.dkr.ecr.cn-north-1.amazonaws.com.cn/sd3-compyui-notebook-7-11\",\n",
      "            \"createdAt\": 1720698326.499,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "{\n",
      "    \"registryId\": \"415056049790\",\n",
      "    \"repositoryName\": \"sd3-compyui-notebook-7-11\",\n",
      "    \"policyText\": \"{\\n  \\\"Version\\\" : \\\"2008-10-17\\\",\\n  \\\"Statement\\\" : [ {\\n    \\\"Sid\\\" : \\\"new statement\\\",\\n    \\\"Effect\\\" : \\\"Allow\\\",\\n    \\\"Principal\\\" : \\\"*\\\",\\n    \\\"Action\\\" : [ \\\"ecr: CompleteLayerUpload\\\", \\\"ecr: InitiateLayerUpload\\\", \\\"ecr: ListImages\\\", \\\"ecr:BatchCheckLayerAvailability\\\", \\\"ecr:BatchGetImage\\\", \\\"ecr:DescribeImages\\\", \\\"ecr:DescribeRepositories\\\", \\\"ecr:GetDownloadUrlForLayer\\\" ]\\n  } ]\\n}\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile.inference\n",
      "#1 transferring dockerfile: 590B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [auth] sharing credentials for 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/pytorch-inference:2.3.0-gpu-py311\n",
      "#3 DONE 0.1s\n",
      "\n",
      "#4 [internal] load .dockerignore\n",
      "#4 transferring context: 2B done\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [ 1/10] FROM 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/pytorch-inference:2.3.0-gpu-py311@sha256:1a5b621b7e15af17a989af9628ceef820984b2a589dd442a654098564fd4b5f2\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [ 3/10] WORKDIR /opt/ml/code\n",
      "#6 CACHED\n",
      "\n",
      "#7 [ 2/10] RUN mkdir -p /opt/ml/code\n",
      "#7 CACHED\n",
      "\n",
      "#8 [ 4/10] RUN git clone https://github.com/comfyanonymous/ComfyUI.git /opt/ml/code\n",
      "#8 CACHED\n",
      "\n",
      "#9 [internal] load build context\n",
      "#9 transferring context: 374B done\n",
      "#9 DONE 0.0s\n",
      "\n",
      "#10 [ 5/10] RUN pip install -r requirements.txt\n",
      "#10 0.601 Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.3.0+cu121)\n",
      "#10 0.786 Collecting torchsde (from -r requirements.txt (line 2))\n",
      "#10 0.976   Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
      "#10 0.983 Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.18.0+cu121)\n",
      "#10 0.984 Requirement already satisfied: torchaudio in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.3.0+cu121)\n",
      "#10 1.051 Collecting einops (from -r requirements.txt (line 5))\n",
      "#10 1.111   Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "#10 1.321 Collecting transformers>=4.28.1 (from -r requirements.txt (line 6))\n",
      "#10 1.381   Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "#10 1.448      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 564.1 kB/s eta 0:00:00\n",
      "#10 1.981 Collecting tokenizers>=0.13.3 (from -r requirements.txt (line 7))\n",
      "#10 2.042   Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "#10 2.223 Collecting sentencepiece (from -r requirements.txt (line 8))\n",
      "#10 2.285   Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "#10 2.593 Collecting safetensors>=0.4.2 (from -r requirements.txt (line 9))\n",
      "#10 2.654   Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "#10 3.361 Collecting aiohttp (from -r requirements.txt (line 10))\n",
      "#10 3.424   Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "#10 3.432 Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "#10 3.434 Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (10.3.0)\n",
      "#10 3.435 Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (1.13.1)\n",
      "#10 3.438 Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (4.66.4)\n",
      "#10 3.439 Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (5.9.8)\n",
      "#10 3.524 Collecting kornia>=0.7.1 (from -r requirements.txt (line 18))\n",
      "#10 3.585   Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "#10 3.662 Collecting spandrel (from -r requirements.txt (line 19))\n",
      "#10 3.723   Downloading spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)\n",
      "#10 3.805 Collecting soundfile (from -r requirements.txt (line 20))\n",
      "#10 3.866   Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "#10 3.884 Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.14.0)\n",
      "#10 3.885 Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
      "#10 3.886 Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (1.12.1)\n",
      "#10 3.887 Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
      "#10 3.888 Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
      "#10 3.889 Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (2024.6.0)\n",
      "#10 3.894 Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.11/site-packages (from torchsde->-r requirements.txt (line 2)) (1.26.4)\n",
      "#10 3.960 Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n",
      "#10 4.020   Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
      "#10 4.452 Collecting huggingface-hub<1.0,>=0.23.2 (from transformers>=4.28.1->-r requirements.txt (line 6))\n",
      "#10 4.512   Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "#10 4.526 Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (23.2)\n",
      "#10 6.191 Collecting regex!=2019.12.17 (from transformers>=4.28.1->-r requirements.txt (line 6))\n",
      "#10 6.252   Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "#10 6.319      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 6.7 MB/s eta 0:00:00\n",
      "#10 6.324 Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2.32.3)\n",
      "#10 6.447 Collecting aiosignal>=1.1.2 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 6.507   Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "#10 6.599 Collecting attrs>=17.3.0 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 6.659   Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "#10 6.929 Collecting frozenlist>=1.1.1 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 6.990   Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "#10 7.933 Collecting multidict<7.0,>=4.5 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 7.993   Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "#10 8.675 Collecting yarl<2.0,>=1.0 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 8.737   Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "#10 8.988 Collecting kornia-rs>=0.1.0 (from kornia>=0.7.1->-r requirements.txt (line 18))\n",
      "#10 9.050   Downloading kornia_rs-0.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "#10 9.072 Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile->-r requirements.txt (line 20)) (1.16.0)\n",
      "#10 9.098 Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 20)) (2.21)\n",
      "#10 9.260 Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 10)) (3.7)\n",
      "#10 9.282 Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
      "#10 9.309 Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (3.3.2)\n",
      "#10 9.313 Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (1.26.19)\n",
      "#10 9.314 Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2024.7.4)\n",
      "#10 9.319 Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "#10 9.432 Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
      "#10 9.482    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 1.3 MB/s eta 0:00:00\n",
      "#10 9.543 Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "#10 9.581    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.2/43.2 kB 1.3 MB/s eta 0:00:00\n",
      "#10 9.706 Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "#10 43.18    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 258.7 kB/s eta 0:00:00\n",
      "#10 43.25 Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "#10 56.83    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 265.6 kB/s eta 0:00:00\n",
      "#10 56.89 Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "#10 61.93    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 258.2 kB/s eta 0:00:00\n",
      "#10 61.99 Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "#10 66.82    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 251.8 kB/s eta 0:00:00\n",
      "#10 66.88 Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "#10 73.60    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 193.6 kB/s eta 0:00:00\n",
      "#10 73.66 Downloading kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n",
      "#10 76.62    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 833.3/833.3 kB 280.9 kB/s eta 0:00:00\n",
      "#10 76.68 Downloading spandrel-0.3.4-py3-none-any.whl (268 kB)\n",
      "#10 78.00    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 269.0/269.0 kB 207.5 kB/s eta 0:00:00\n",
      "#10 78.06 Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "#10 81.56    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 339.7 kB/s eta 0:00:00\n",
      "#10 81.62 Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "#10 81.70 Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "#10 81.84    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 kB 459.0 kB/s eta 0:00:00\n",
      "#10 81.90 Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "#10 82.45    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.3/272.3 kB 508.2 kB/s eta 0:00:00\n",
      "#10 82.51 Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "#10 83.29    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.6/402.6 kB 514.9 kB/s eta 0:00:00\n",
      "#10 83.35 Downloading kornia_rs-0.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "#10 87.77    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 372.1 kB/s eta 0:00:00\n",
      "#10 87.83 Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "#10 88.15    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 kB 412.7 kB/s eta 0:00:00\n",
      "#10 88.22 Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "#10 90.85    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.0/785.0 kB 297.3 kB/s eta 0:00:00\n",
      "#10 90.91 Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
      "#10 90.99 Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "#10 92.22    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 328.1/328.1 kB 272.3 kB/s eta 0:00:00\n",
      "#10 93.36 Installing collected packages: trampoline, sentencepiece, safetensors, regex, multidict, kornia-rs, frozenlist, einops, attrs, yarl, soundfile, huggingface-hub, aiosignal, torchsde, tokenizers, kornia, aiohttp, transformers, spandrel\n",
      "#10 99.71 Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 einops-0.8.0 frozenlist-1.4.1 huggingface-hub-0.23.4 kornia-0.7.3 kornia-rs-0.1.5 multidict-6.0.5 regex-2024.5.15 safetensors-0.4.3 sentencepiece-0.2.0 soundfile-0.12.1 spandrel-0.3.4 tokenizers-0.19.1 torchsde-0.2.6 trampoline-0.1.2 transformers-4.42.4 yarl-1.9.4\n",
      "#10 99.71 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#10 99.82 \n",
      "#10 99.82 [notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "#10 99.82 [notice] To update, run: pip install --upgrade pip\n",
      "#10 DONE 100.8s\n",
      "\n",
      "#11 [ 6/10] RUN path='pwd'\n",
      "#11 DONE 0.2s\n",
      "\n",
      "#12 [ 7/10] RUN echo $path\n",
      "#12 0.257 \n",
      "#12 DONE 0.3s\n",
      "\n",
      "#13 [ 8/10] COPY /ComfyUI-master/models/checkpoints/sd3_medium_incl_clips.safetensors /opt/ml/code/models/checkpoints/\n",
      "#13 DONE 57.2s\n",
      "\n",
      "#14 [ 9/10] COPY /ComfyUI-master/models/vae/diffusion_pytorch_model.safetensors /opt/ml/code/models/vae/\n",
      "#14 DONE 3.4s\n",
      "\n",
      "#15 [10/10] COPY serve /opt/ml/code\n",
      "#15 DONE 0.0s\n",
      "\n",
      "#16 exporting to image\n",
      "#16 exporting layers\n",
      "#16 exporting layers 22.6s done\n",
      "#16 writing image sha256:87408b2fa38451d829810f2c7db4a42f437d38507546bf3df11075f5d4e3151f done\n",
      "#16 naming to docker.io/library/sd3-compyui-notebook-7-11 done\n",
      "#16 DONE 22.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [415056049790.dkr.ecr.cn-north-1.amazonaws.com.cn/sd3-compyui-notebook-7-11]\n",
      "4f57158c2ca4: Preparing\n",
      "35d882d91a5a: Preparing\n",
      "7989612c6aed: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "fef069097b59: Preparing\n",
      "ae856c1a8554: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "b353e8f30fed: Preparing\n",
      "02428eed6535: Preparing\n",
      "4a0a5c128293: Preparing\n",
      "3e6a356c8e45: Preparing\n",
      "484aaa05a493: Preparing\n",
      "48786340ab74: Preparing\n",
      "5b0bdb8eec88: Preparing\n",
      "348f0dd546ad: Preparing\n",
      "b89286a316e3: Preparing\n",
      "87253ce52fc2: Preparing\n",
      "dc1df578e095: Preparing\n",
      "a976e35b0162: Preparing\n",
      "9020defa345e: Preparing\n",
      "2243997e691d: Preparing\n",
      "51e59867d98a: Preparing\n",
      "8b942a46ff73: Preparing\n",
      "2316d1d13f80: Preparing\n",
      "23aa9e3f79b2: Preparing\n",
      "1de5b0cf4a95: Preparing\n",
      "2b4ab9c66c33: Preparing\n",
      "4c4b5ef162c6: Preparing\n",
      "def14ac3e467: Preparing\n",
      "ab8967843163: Preparing\n",
      "46d81ba1b88f: Preparing\n",
      "cca198a3aa21: Preparing\n",
      "6e2c6cec7c79: Preparing\n",
      "1165bb2e119f: Preparing\n",
      "ef177fb935b3: Preparing\n",
      "5cb9ea7abb90: Preparing\n",
      "5f0f06d0dbe1: Preparing\n",
      "7623c51736a6: Preparing\n",
      "b07ea64c8933: Preparing\n",
      "9dbd6d766fae: Preparing\n",
      "8d78458ccbe2: Preparing\n",
      "f620bf47e83d: Preparing\n",
      "5c0359201b8f: Preparing\n",
      "6c3e7df31590: Preparing\n",
      "ae856c1a8554: Waiting\n",
      "b353e8f30fed: Waiting\n",
      "02428eed6535: Waiting\n",
      "4a0a5c128293: Waiting\n",
      "3e6a356c8e45: Waiting\n",
      "484aaa05a493: Waiting\n",
      "48786340ab74: Waiting\n",
      "5b0bdb8eec88: Waiting\n",
      "348f0dd546ad: Waiting\n",
      "b89286a316e3: Waiting\n",
      "87253ce52fc2: Waiting\n",
      "dc1df578e095: Waiting\n",
      "a976e35b0162: Waiting\n",
      "9020defa345e: Waiting\n",
      "2243997e691d: Waiting\n",
      "51e59867d98a: Waiting\n",
      "8b942a46ff73: Waiting\n",
      "2316d1d13f80: Waiting\n",
      "1de5b0cf4a95: Waiting\n",
      "23aa9e3f79b2: Waiting\n",
      "4c4b5ef162c6: Waiting\n",
      "def14ac3e467: Waiting\n",
      "2b4ab9c66c33: Waiting\n",
      "ab8967843163: Waiting\n",
      "5f0f06d0dbe1: Waiting\n",
      "7623c51736a6: Waiting\n",
      "46d81ba1b88f: Waiting\n",
      "b07ea64c8933: Waiting\n",
      "cca198a3aa21: Waiting\n",
      "9dbd6d766fae: Waiting\n",
      "6e2c6cec7c79: Waiting\n",
      "8d78458ccbe2: Waiting\n",
      "5cb9ea7abb90: Waiting\n",
      "1165bb2e119f: Waiting\n",
      "f620bf47e83d: Waiting\n",
      "ef177fb935b3: Waiting\n",
      "5c0359201b8f: Waiting\n",
      "6c3e7df31590: Waiting\n",
      "5f70bf18a086: Layer already exists\n",
      "4f57158c2ca4: Pushed\n",
      "b353e8f30fed: Pushed\n",
      "ae856c1a8554: Pushed\n",
      "02428eed6535: Pushed\n",
      "3e6a356c8e45: Pushed\n",
      "484aaa05a493: Pushed\n",
      "48786340ab74: Layer already exists\n",
      "5b0bdb8eec88: Layer already exists\n",
      "348f0dd546ad: Layer already exists\n",
      "b89286a316e3: Layer already exists\n",
      "87253ce52fc2: Layer already exists\n",
      "dc1df578e095: Layer already exists\n",
      "a976e35b0162: Layer already exists\n",
      "9020defa345e: Layer already exists\n",
      "2243997e691d: Layer already exists\n",
      "51e59867d98a: Layer already exists\n",
      "8b942a46ff73: Layer already exists\n",
      "2316d1d13f80: Layer already exists\n",
      "23aa9e3f79b2: Layer already exists\n",
      "1de5b0cf4a95: Layer already exists\n",
      "2b4ab9c66c33: Layer already exists\n",
      "4c4b5ef162c6: Layer already exists\n",
      "def14ac3e467: Layer already exists\n",
      "ab8967843163: Layer already exists\n",
      "46d81ba1b88f: Layer already exists\n",
      "cca198a3aa21: Layer already exists\n",
      "6e2c6cec7c79: Layer already exists\n",
      "1165bb2e119f: Layer already exists\n",
      "ef177fb935b3: Layer already exists\n",
      "5cb9ea7abb90: Layer already exists\n",
      "5f0f06d0dbe1: Layer already exists\n",
      "7623c51736a6: Layer already exists\n",
      "b07ea64c8933: Layer already exists\n",
      "9dbd6d766fae: Layer already exists\n",
      "8d78458ccbe2: Layer already exists\n",
      "f620bf47e83d: Layer already exists\n",
      "5c0359201b8f: Layer already exists\n",
      "6c3e7df31590: Layer already exists\n",
      "4a0a5c128293: Pushed\n",
      "fef069097b59: Pushed\n",
      "35d882d91a5a: Pushed\n",
      "7989612c6aed: Pushed\n",
      "latest: digest: sha256:b0e31bdb36f9f8033c32336da537f1abd37d4e5912928a8256c861d8aa6ba3c6 size: 9751\n"
     ]
    }
   ],
   "source": [
    "%%sh -s \"$region_name\" \"$role\" \"$bucket\" \"$account_id\" \"$inference_image\"\n",
    "region=$1\n",
    "account=$4\n",
    "inference_image=$5\n",
    "echo $region   $account\n",
    "aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $account.dkr.ecr.$region.amazonaws.com.cn\n",
    "\n",
    "inference_fullname=$account.dkr.ecr.$region.amazonaws.com.cn/$inference_image:latest\n",
    "echo $inference_fullname\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${inference_image}\" --region $region || aws ecr create-repository --repository-name \"$inference_image\" --region $region\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${inference_image}\" --region ${region}\n",
    "    echo \"I am here created new ECR Repo $inference_image\"\n",
    "fi\n",
    "\n",
    "AWSchinaAccount=\"727897471807\"\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "docker login -u AWS -p $(aws ecr get-login-password --region $region) $AWSchinaAccount.dkr.ecr.$region.amazonaws.com.cn\n",
    "\n",
    "aws ecr set-repository-policy \\\n",
    "    --repository-name \"${inference_image}\" \\\n",
    "    --policy-text \"file://ecr-policy.json\" \\\n",
    "    --region ${region}\n",
    "\n",
    "docker build -t ${inference_image} -f Dockerfile.inference . --build-arg REGION=$region\n",
    "\n",
    "\n",
    "docker tag ${inference_image} ${inference_fullname}\n",
    "\n",
    "docker push ${inference_fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac742d7-c1b1-4bf9-aad1-60b28296f595",
   "metadata": {},
   "source": [
    "Upload the dummy file to S3 to meet the requirement of SageMaker Endpoint for model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3686c6d8-ae5e-490f-b9d2-163a5a199a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n",
      "upload: ./model.tar.gz to s3://sagemaker-cn-north-1-415056049790/SD3-ComfyUI-fake/data/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data = \"s3://{0}/SD3-ComfyUI-fake/data/model.tar.gz\".format(bucket)\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "!rm dummy\n",
    "!aws s3 cp model.tar.gz $model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71cbd8-d3b0-4771-b40e-bc2e98afa673",
   "metadata": {},
   "source": [
    "## Deploy to SageMaker Asychronous Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2094f3ae-362f-4fa5-b2de-c4dcb6463542",
   "metadata": {},
   "source": [
    "Initialized the variables for URI of Docker Inference Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08489692-2df3-4833-905c-2e0a6b59e962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415056049790.dkr.ecr.cn-north-1.amazonaws.com.cn/sd3-compyui-notebook-7-11:latest\n"
     ]
    }
   ],
   "source": [
    "model_name = None\n",
    "image_uri = \"{0}.dkr.ecr.{1}.amazonaws.com.cn/{2}:latest\".format(\n",
    "    account_id, region_name, inference_image\n",
    ")\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e013c82-4839-4663-a588-19aa115486f7",
   "metadata": {},
   "source": [
    "Define the models configuration in order to download those models from one of source - HTTP, S3 and HuggingFace. Note: Here as an example the Lora model - 2bNierAutomataLora_v2b.safetensors and ControlNet model - control_sd15_canny.pth are going to be downloaded from Civitai and Huggingface directly once the SageMaker endpoint is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfb7716-7fbf-4d3e-9228-9d4c866c5d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# comments out\n",
    "import json\n",
    "\n",
    "huggingface_models = [\n",
    "    {\n",
    "\n",
    "    }\n",
    "]\n",
    "\n",
    "model_environment = {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b936a1a7-0dcd-4d82-be5b-08a6ae447930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "huggingface_models = [\n",
    "    {\n",
    "    }\n",
    "]\n",
    "\n",
    "model_environment = {\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba80cbb-fac7-4425-850a-8c3b7c4a205d",
   "metadata": {},
   "source": [
    "Define the model, instance type and instance initial count for SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ee5b8ac-0d4b-4dae-9561-dbf8f3580237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    env=model_environment,\n",
    "    predictor_cls=Predictor,\n",
    ")\n",
    "\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc946fb-e790-4beb-b519-8e4264ed1aa1",
   "metadata": {},
   "source": [
    "Define the SageMaker Asychronous Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b72569-91fa-4192-9c63-a5173485a755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=\"s3://{0}/{1}/asyncinvoke/out/\".format(bucket, \"sd3-comfyui\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e5c97-c33a-450e-aa80-bf5318225265",
   "metadata": {},
   "source": [
    "Here we use asynchronous inference since asynchronous inference is more suitable for workloads with large payload sizes and long inference processing times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513a98c-78ea-4893-98cf-314dc7278715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=instance_count,\n",
    "    container_startup_health_check_timeout=1800,\n",
    "    async_inference_config=async_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f488f-6024-46b8-8364-642fc89487a1",
   "metadata": {},
   "source": [
    "## Generate initial image using text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d9d25-2074-4b29-a437-4530d7cff5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"text-to-image\",\n",
    "    \"txt2img_payload\": {\n",
    "        \"prompt\": \"((Best quality)), ((masterpiece)), ((realistic)), (detailed), cute panda ((standing in a asian garden with cherry trees)) ((masterpiece)), absurdres, HDR\",\n",
    "        \"negative_prompt\": \"(bad quality)\",\n",
    "        \"seed\": 2816240246,\n",
    "        \"sampler_name\": \"Euler a\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": 20,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"width\": 512,\n",
    "        \"height\": 768,\n",
    "        \"alwayson_scripts\": {},\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a369c699-5d63-400a-8f43-c2474ef52da4",
   "metadata": {},
   "source": [
    "Helper function for S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ebf380-7126-4118-9f1f-932ec75f2c65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find(\"/\", 5)\n",
    "    bucket = s3uri[5:pos]\n",
    "    key = s3uri[pos + 1 :]\n",
    "    return bucket, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbaee6-3732-4f21-8260-91cbe56748d5",
   "metadata": {},
   "source": [
    "Wait until the asychronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a4069-cacc-4721-8c4b-d5468efb643a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ace299-f064-4f5b-b4d7-d2a98e72869f",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f831db6-a9ce-429f-a0af-18055af7bc02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    image_object = json.loads(body)[\"images\"][0]\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_object)))\n",
    "    image.show()\n",
    "    initial_image_filename = datetime.now().strftime(f\"%Y%m%d%H%M%S-{uuid.uuid4()}.png\")\n",
    "    image.save(initial_image_filename)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57075b0-9b48-492e-9d6b-4c236bf3301b",
   "metadata": {},
   "source": [
    "## Expand initial image using text prompt and ControlNet models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b1d29-9ba8-4ba9-87c9-d970ab85e0d7",
   "metadata": {},
   "source": [
    "ControlNet is a neural network structure to control diffusion models by adding extra conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763fd5c-e82d-45ac-8311-1c9a17df161a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    with io.BytesIO() as output_bytes:\n",
    "        if isinstance(image, dict):\n",
    "            image = image[\"image\"]\n",
    "        format = \"PNG\" if image.mode == \"RGBA\" else \"JPEG\"\n",
    "        image.save(output_bytes, format=format)\n",
    "        bytes_data = output_bytes.getvalue()\n",
    "\n",
    "    encoded_string = base64.b64encode(bytes_data)\n",
    "\n",
    "    base64_str = str(encoded_string, \"utf-8\")\n",
    "    mimetype = \"image/jpeg\" if format == \"JPEG\" else \"image/png\"\n",
    "    image_encoded_in_base64 = (\n",
    "        \"data:\" + (mimetype if mimetype is not None else \"\") + \";base64,\" + base64_str\n",
    "    )\n",
    "    return image_encoded_in_base64\n",
    "\n",
    "\n",
    "def decode_base64_to_image(encoding):\n",
    "    if encoding.startswith(\"data:image/\"):\n",
    "        encoding = encoding.split(\";\")[1].split(\",\")[1]\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(encoding)))\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b8a8e-8d42-4c3e-9b64-5a5d8a7ce3f3",
   "metadata": {},
   "source": [
    "Define the payload for SageMaker inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35fc868-7a35-4ebf-accb-4fae77af13cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"image-to-image\",\n",
    "    \"img2img_payload\": {\n",
    "        \"prompt\": \"((Best quality)), ((masterpiece)), ((realistic)), (detailed), cute panda ((standing in a asian garden with cherry trees)) ((masterpiece)), absurdres, HDR\",\n",
    "        \"negative_prompt\": \"(bad quality)\",\n",
    "        \"init_images\": [encode_image_to_base64(image)],\n",
    "        \"mask\": None,\n",
    "        \"steps\": 20,\n",
    "        \"sampler_name\": \"Euler a\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"denoising_strength\": 0.8,\n",
    "        \"seed\": 2866147124,\n",
    "        \"height\": 768,\n",
    "        \"width\": 1280,\n",
    "        \"resize_mode\": 0,\n",
    "        \"include_init_images\": False,\n",
    "        \"alwayson_scripts\": {\n",
    "            \"controlnet\": {\n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"enabled\": True,\n",
    "                        \"module\": \"inpaint_only+lama\",\n",
    "                        \"model\": \"control_v11p_sd15_inpaint [ebff9138]\",\n",
    "                        \"image\": encode_image_to_base64(image),\n",
    "                        \"resize_mode\": \"Resize and Fill\",\n",
    "                        \"low_vram\": False,\n",
    "                        \"weight\": 1,\n",
    "                        \"guidance_start\": 0,\n",
    "                        \"guidance_end\": 1,\n",
    "                        \"pixel_perfect\": False,\n",
    "                        \"control_mode\": \"ControlNet is more important\",\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5a049c-7ef0-4347-a703-6cfb7a229505",
   "metadata": {},
   "source": [
    "Wait until the asynchronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b49508-348e-47e3-aebf-34656dba5158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a71b9-11fb-4f7b-a093-ba46f724bbf0",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a3335-5441-467f-8cc3-db745903cdfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    image_object = json.loads(body)[\"images\"][0]\n",
    "    image2 = Image.open(BytesIO(base64.b64decode(image_object)))\n",
    "    image2.show()\n",
    "    image2.save(datetime.now().strftime(f\"%Y%m%d%H%M%S-{uuid.uuid4()}.png\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8c2a3-f800-49ec-87ae-8d42581648f5",
   "metadata": {},
   "source": [
    "## Run generative fill application built with Gradio framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a5e5d-7250-481e-a898-5aab78cc2878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c907a7a-8006-4fa4-885f-8b1699a84c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/xieyongliang/generative-fill-webui.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcb160-3679-4124-b694-52c900a04c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd ./generative-fill-webui && export sagemaker_endpoint=$endpoint_name && pip install -r requirements.txt && python ui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f9570-6b5e-48fe-9794-11d31d4498c8",
   "metadata": {},
   "source": [
    "## [Optional] Create auto-scaling group for SageMaker endpoint in case you want to scale it based on specific metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b45375-8c4b-42f8-9eff-a52ef8490cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoscaling_group_for_sagemaker_endpoint(\n",
    "    endpoint_name, min_capcity=1, max_capcity=2, target_value=5\n",
    "):\n",
    "    # application-autoscaling client\n",
    "    asg_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "    # This is the format in which application autoscaling references the endpoint\n",
    "    resource_id = f\"endpoint/{endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "    # Configure Autoscaling on asynchronous endpoint down to zero instances\n",
    "    response = asg_client.register_scalable_target(\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        MinCapacity=min_capcity,\n",
    "        MaxCapacity=max_capcity,\n",
    "    )\n",
    "\n",
    "    response = asg_client.put_scaling_policy(\n",
    "        PolicyName=f\"Request-ScalingPolicy-{endpoint_name}\",\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        PolicyType=\"TargetTrackingScaling\",\n",
    "        TargetTrackingScalingPolicyConfiguration={\n",
    "            \"TargetValue\": target_value,\n",
    "            \"CustomizedMetricSpecification\": {\n",
    "                \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n",
    "                \"Namespace\": \"AWS/SageMaker\",\n",
    "                \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": endpoint_name}],\n",
    "                \"Statistic\": \"Average\",\n",
    "            },\n",
    "            \"ScaleInCooldown\": 600,  # duration until scale in begins (down to zero)\n",
    "            \"ScaleOutCooldown\": 300,  # duration between scale out attempts\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "create_autoscaling_group_for_sagemaker_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d89ef-34d8-4da8-b3c6-6ac9671e4337",
   "metadata": {},
   "source": [
    "## Resource cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba3039-c6a1-4873-86fc-cb4f3c91ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49650af8-f937-4c93-af38-669e6e29bd8e",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
