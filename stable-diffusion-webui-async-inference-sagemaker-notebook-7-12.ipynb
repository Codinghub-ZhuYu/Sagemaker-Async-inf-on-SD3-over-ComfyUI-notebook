{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23038a32",
   "metadata": {},
   "source": [
    "# Generative Fill example on Amazon SageMaker using DLC container.\n",
    "\n",
    "In this notebook, we explore how to build generative fill application and host Stable Diffusion/ ControlNet / segment anything models on SageMaker asynchronous endpoint using BYOC (Bring-your-own-container).\n",
    "\n",
    "In this notebook, under the hood we use stable-diffusion-webui and extensions to generate image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ea0b4",
   "metadata": {},
   "source": [
    "Note - Amazon Web Services has no control or authority over the third-party generative AI service referenced in this Workshop, and does not make any representations or warranties that the third-party generative AI service is secure, virus-free, operational, or compatible with your production environment and standards. You are responsible for making your own independent assessment of the content provided in this Workshop, and take measures to ensure that you comply with your own specific quality control practices and standards, and the local rules, laws, regulations, licenses and terms of use that apply to you, your content, and the third-party generative AI service referenced in this Workshop. The content of this Workshop: (a) is for informational purposes only, (b) represents current Amazon Web Services product offerings and practices, which are subject to change without notice, and (c) does not create any commitments or assurances from Beijing Sinnet Technology Co., Ltd. (“Sinnet”), Ningxia Western Cloud Data Technology Co., Ltd. (“NWCD”), Amazon Connect Technology Services (Beijing) Co., Ltd. (“Amazon”), or their respective affiliates, suppliers or licensors.  Amazon Web Services’ content, products or services are provided “as is” without warranties, representations, or conditions of any kind, whether express or implied.  The responsibilities and liabilities of Sinnet, NWCD or Amazon to their respective customers are controlled by the applicable customer agreements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b66d6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook.\n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc02c01",
   "metadata": {},
   "source": [
    "## Build Docker image and push to ECR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fabca7",
   "metadata": {},
   "source": [
    "Initialize the variables for SageMaker default bucket, role, and AWS account ID, and current AWS region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e3ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3 \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role=\"AmazonSageMaker-ExecutionRole-20220920T203057\"\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "region_name = boto3.session.Session().region_name\n",
    "inference_image=\"sd3-compyui-notebook-7-12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76fe6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn-north-1 415056049790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "415056049790.dkr.ecr.cn-north-1.amazonaws.com.cn/sd3-compyui-notebook-7-12:latest\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws-cn:ecr:cn-north-1:415056049790:repository/sd3-compyui-notebook-7-12\",\n",
      "            \"registryId\": \"415056049790\",\n",
      "            \"repositoryName\": \"sd3-compyui-notebook-7-12\",\n",
      "            \"repositoryUri\": \"415056049790.dkr.ecr.cn-north-1.amazonaws.com.cn/sd3-compyui-notebook-7-12\",\n",
      "            \"createdAt\": 1720766584.784,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "{\n",
      "    \"registryId\": \"415056049790\",\n",
      "    \"repositoryName\": \"sd3-compyui-notebook-7-12\",\n",
      "    \"policyText\": \"{\\n  \\\"Version\\\" : \\\"2008-10-17\\\",\\n  \\\"Statement\\\" : [ {\\n    \\\"Sid\\\" : \\\"new statement\\\",\\n    \\\"Effect\\\" : \\\"Allow\\\",\\n    \\\"Principal\\\" : \\\"*\\\",\\n    \\\"Action\\\" : [ \\\"ecr: CompleteLayerUpload\\\", \\\"ecr: InitiateLayerUpload\\\", \\\"ecr: ListImages\\\", \\\"ecr:BatchCheckLayerAvailability\\\", \\\"ecr:BatchGetImage\\\", \\\"ecr:DescribeImages\\\", \\\"ecr:DescribeRepositories\\\", \\\"ecr:GetDownloadUrlForLayer\\\" ]\\n  } ]\\n}\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile.inference\n",
      "#1 transferring dockerfile: 610B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [auth] sharing credentials for 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/pytorch-inference:2.3.0-gpu-py311\n",
      "#3 DONE 0.1s\n",
      "\n",
      "#4 [internal] load .dockerignore\n",
      "#4 transferring context: 2B done\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [ 1/10] FROM 727897471807.dkr.ecr.cn-north-1.amazonaws.com.cn/pytorch-inference:2.3.0-gpu-py311@sha256:1a5b621b7e15af17a989af9628ceef820984b2a589dd442a654098564fd4b5f2\n",
      "#5 CACHED\n",
      "\n",
      "#6 [internal] load build context\n",
      "#6 transferring context: 374B done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [ 2/10] RUN mkdir -p /opt/ml/code\n",
      "#7 DONE 0.2s\n",
      "\n",
      "#8 [ 3/10] WORKDIR /opt/ml/code\n",
      "#8 DONE 0.0s\n",
      "\n",
      "#9 [ 4/10] RUN git clone https://github.com/Codinghub-ZhuYu/ComfyUI-SageMaker-Async-inf.git /opt/ml/code\n",
      "#9 0.267 Cloning into '/opt/ml/code'...\n",
      "#9 DONE 3.2s\n",
      "\n",
      "#10 [ 5/10] RUN pip install -r requirements.txt\n",
      "#10 1.197 Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.3.0+cu121)\n",
      "#10 1.559 Collecting torchsde (from -r requirements.txt (line 2))\n",
      "#10 2.130   Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
      "#10 2.138 Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.18.0+cu121)\n",
      "#10 2.139 Requirement already satisfied: torchaudio in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.3.0+cu121)\n",
      "#10 2.382 Collecting einops (from -r requirements.txt (line 5))\n",
      "#10 2.453   Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "#10 2.651 Collecting transformers>=4.28.1 (from -r requirements.txt (line 6))\n",
      "#10 2.995   Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "#10 3.098      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 406.4 kB/s eta 0:00:00\n",
      "#10 3.784 Collecting tokenizers>=0.13.3 (from -r requirements.txt (line 7))\n",
      "#10 3.854   Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "#10 4.077 Collecting sentencepiece (from -r requirements.txt (line 8))\n",
      "#10 4.436   Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "#10 4.829 Collecting safetensors>=0.4.2 (from -r requirements.txt (line 9))\n",
      "#10 4.898   Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "#10 5.690 Collecting aiohttp (from -r requirements.txt (line 10))\n",
      "#10 6.899   Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "#10 6.920 Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "#10 6.921 Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (10.3.0)\n",
      "#10 6.922 Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (1.13.1)\n",
      "#10 6.925 Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (4.66.4)\n",
      "#10 6.926 Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (5.9.8)\n",
      "#10 7.009 Collecting kornia>=0.7.1 (from -r requirements.txt (line 18))\n",
      "#10 7.077   Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "#10 7.170 Collecting spandrel (from -r requirements.txt (line 19))\n",
      "#10 7.240   Downloading spandrel-0.3.4-py3-none-any.whl.metadata (14 kB)\n",
      "#10 7.346 Collecting soundfile (from -r requirements.txt (line 20))\n",
      "#10 7.416   Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
      "#10 7.458 Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.14.0)\n",
      "#10 7.459 Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
      "#10 7.460 Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (1.12.1)\n",
      "#10 7.461 Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
      "#10 7.462 Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
      "#10 7.464 Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (2024.6.0)\n",
      "#10 7.469 Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.11/site-packages (from torchsde->-r requirements.txt (line 2)) (1.26.4)\n",
      "#10 7.534 Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n",
      "#10 7.890   Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
      "#10 8.263 Collecting huggingface-hub<1.0,>=0.23.2 (from transformers>=4.28.1->-r requirements.txt (line 6))\n",
      "#10 8.332   Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "#10 8.373 Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (23.2)\n",
      "#10 9.449 Collecting regex!=2019.12.17 (from transformers>=4.28.1->-r requirements.txt (line 6))\n",
      "#10 9.520   Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "#10 9.620      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 485.5 kB/s eta 0:00:00\n",
      "#10 9.625 Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers>=4.28.1->-r requirements.txt (line 6)) (2.32.3)\n",
      "#10 9.745 Collecting aiosignal>=1.1.2 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 9.814   Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "#10 9.905 Collecting attrs>=17.3.0 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 9.975   Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "#10 10.19 Collecting frozenlist>=1.1.1 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 10.26   Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "#10 11.04 Collecting multidict<7.0,>=4.5 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 11.11   Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "#10 11.67 Collecting yarl<2.0,>=1.0 (from aiohttp->-r requirements.txt (line 10))\n",
      "#10 11.74   Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "#10 12.06 Collecting kornia-rs>=0.1.0 (from kornia>=0.7.1->-r requirements.txt (line 18))\n",
      "#10 12.40   Downloading kornia_rs-0.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "#10 12.45 Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile->-r requirements.txt (line 20)) (1.16.0)\n",
      "#10 12.47 Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 20)) (2.21)\n",
      "#10 12.64 Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 10)) (3.7)\n",
      "#10 12.66 Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
      "#10 12.69 Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (3.3.2)\n",
      "#10 12.69 Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (1.26.19)\n",
      "#10 12.69 Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 6)) (2024.7.4)\n",
      "#10 12.70 Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "#10 17.11 Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
      "#10 17.29    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 362.5 kB/s eta 0:00:00\n",
      "#10 17.36 Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "#10 17.48    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.2/43.2 kB 373.0 kB/s eta 0:00:00\n",
      "#10 17.54 Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "#10 47.49    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 311.8 kB/s eta 0:00:00\n",
      "#10 47.56 Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "#10 61.52    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 259.2 kB/s eta 0:00:00\n",
      "#10 61.58 Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "#10 66.22    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 281.3 kB/s eta 0:00:00\n",
      "#10 66.58 Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "#10 70.11    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 341.6 kB/s eta 0:00:00\n",
      "#10 70.18 Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "#10 73.28    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 419.1 kB/s eta 0:00:00\n",
      "#10 73.35 Downloading kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n",
      "#10 76.42    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 833.3/833.3 kB 270.7 kB/s eta 0:00:00\n",
      "#10 76.49 Downloading spandrel-0.3.4-py3-none-any.whl (268 kB)\n",
      "#10 77.65    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 269.0/269.0 kB 237.6 kB/s eta 0:00:00\n",
      "#10 77.72 Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "#10 81.17    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 341.8 kB/s eta 0:00:00\n",
      "#10 81.52 Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "#10 81.91 Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "#10 82.05    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.8/60.8 kB 479.8 kB/s eta 0:00:00\n",
      "#10 82.12 Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "#10 82.61    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 272.3/272.3 kB 561.8 kB/s eta 0:00:00\n",
      "#10 83.25 Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "#10 83.88    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 402.6/402.6 kB 638.9 kB/s eta 0:00:00\n",
      "#10 83.95 Downloading kornia_rs-0.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "#10 87.81    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 435.8 kB/s eta 0:00:00\n",
      "#10 88.43 Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "#10 88.69    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 kB 500.3 kB/s eta 0:00:00\n",
      "#10 89.33 Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "#10 91.14    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.0/785.0 kB 434.2 kB/s eta 0:00:00\n",
      "#10 91.21 Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
      "#10 91.47 Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "#10 92.32    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 328.1/328.1 kB 419.3 kB/s eta 0:00:00\n",
      "#10 93.49 Installing collected packages: trampoline, sentencepiece, safetensors, regex, multidict, kornia-rs, frozenlist, einops, attrs, yarl, soundfile, huggingface-hub, aiosignal, torchsde, tokenizers, kornia, aiohttp, transformers, spandrel\n",
      "#10 99.92 Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 einops-0.8.0 frozenlist-1.4.1 huggingface-hub-0.23.4 kornia-0.7.3 kornia-rs-0.1.5 multidict-6.0.5 regex-2024.5.15 safetensors-0.4.3 sentencepiece-0.2.0 soundfile-0.12.1 spandrel-0.3.4 tokenizers-0.19.1 torchsde-0.2.6 trampoline-0.1.2 transformers-4.42.4 yarl-1.9.4\n",
      "#10 99.92 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#10 100.0 \n",
      "#10 100.0 [notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "#10 100.0 [notice] To update, run: pip install --upgrade pip\n",
      "#10 DONE 100.9s\n",
      "\n",
      "#11 [ 6/10] RUN path='pwd'\n",
      "#11 DONE 0.2s\n",
      "\n",
      "#12 [ 7/10] RUN echo $path\n",
      "#12 0.211 \n",
      "#12 DONE 0.2s\n",
      "\n",
      "#13 [ 8/10] COPY serve /opt/ml/code\n",
      "#13 DONE 0.0s\n",
      "\n",
      "#14 [ 9/10] COPY /ComfyUI-master/models/checkpoints/sd3_medium_incl_clips.safetensors /opt/ml/code/models/checkpoints/\n",
      "#14 DONE 55.5s\n",
      "\n",
      "#15 [10/10] COPY /ComfyUI-master/models/vae/diffusion_pytorch_model.safetensors /opt/ml/code/models/vae/\n",
      "#15 DONE 3.0s\n",
      "\n",
      "#16 exporting to image\n",
      "#16 exporting layers\n",
      "#16 exporting layers 31.9s done\n",
      "#16 writing image sha256:4dd607c9ee0542976a3adb59ac61c12833913d2892b00b9c5bd1557785aa7448 done\n",
      "#16 naming to docker.io/library/sd3-compyui-notebook-7-12 done\n",
      "#16 DONE 32.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [415056049790.dkr.ecr.cn-north-1.amazonaws.com.cn/sd3-compyui-notebook-7-12]\n",
      "b03af6cdb18c: Preparing\n",
      "86517583b6e1: Preparing\n",
      "11028248fa9c: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "62b141942429: Preparing\n",
      "bfca245d883b: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "4674b64be78d: Preparing\n",
      "02428eed6535: Preparing\n",
      "4a0a5c128293: Preparing\n",
      "3e6a356c8e45: Preparing\n",
      "484aaa05a493: Preparing\n",
      "48786340ab74: Preparing\n",
      "5b0bdb8eec88: Preparing\n",
      "348f0dd546ad: Preparing\n",
      "b89286a316e3: Preparing\n",
      "87253ce52fc2: Preparing\n",
      "dc1df578e095: Preparing\n",
      "a976e35b0162: Preparing\n",
      "9020defa345e: Preparing\n",
      "2243997e691d: Preparing\n",
      "51e59867d98a: Preparing\n",
      "bfca245d883b: Waiting\n",
      "8b942a46ff73: Preparing\n",
      "4674b64be78d: Waiting\n",
      "2316d1d13f80: Preparing\n",
      "02428eed6535: Waiting\n",
      "23aa9e3f79b2: Preparing\n",
      "4a0a5c128293: Waiting\n",
      "3e6a356c8e45: Waiting\n",
      "1de5b0cf4a95: Preparing\n",
      "2b4ab9c66c33: Preparing\n",
      "4c4b5ef162c6: Preparing\n",
      "484aaa05a493: Waiting\n",
      "48786340ab74: Waiting\n",
      "def14ac3e467: Preparing\n",
      "ab8967843163: Preparing\n",
      "46d81ba1b88f: Preparing\n",
      "cca198a3aa21: Preparing\n",
      "6e2c6cec7c79: Preparing\n",
      "1165bb2e119f: Preparing\n",
      "ef177fb935b3: Preparing\n",
      "5cb9ea7abb90: Preparing\n",
      "5f0f06d0dbe1: Preparing\n",
      "7623c51736a6: Preparing\n",
      "b07ea64c8933: Preparing\n",
      "9dbd6d766fae: Preparing\n",
      "8d78458ccbe2: Preparing\n",
      "f620bf47e83d: Preparing\n",
      "5c0359201b8f: Preparing\n",
      "6c3e7df31590: Preparing\n",
      "5b0bdb8eec88: Waiting\n",
      "348f0dd546ad: Waiting\n",
      "b89286a316e3: Waiting\n",
      "87253ce52fc2: Waiting\n",
      "dc1df578e095: Waiting\n",
      "a976e35b0162: Waiting\n",
      "9020defa345e: Waiting\n",
      "2243997e691d: Waiting\n",
      "51e59867d98a: Waiting\n",
      "8b942a46ff73: Waiting\n",
      "2316d1d13f80: Waiting\n",
      "23aa9e3f79b2: Waiting\n",
      "1de5b0cf4a95: Waiting\n",
      "2b4ab9c66c33: Waiting\n",
      "4c4b5ef162c6: Waiting\n",
      "def14ac3e467: Waiting\n",
      "ab8967843163: Waiting\n",
      "46d81ba1b88f: Waiting\n",
      "cca198a3aa21: Waiting\n",
      "6e2c6cec7c79: Waiting\n",
      "1165bb2e119f: Waiting\n",
      "ef177fb935b3: Waiting\n",
      "5cb9ea7abb90: Waiting\n",
      "5f0f06d0dbe1: Waiting\n",
      "7623c51736a6: Waiting\n",
      "b07ea64c8933: Waiting\n",
      "9dbd6d766fae: Waiting\n",
      "8d78458ccbe2: Waiting\n",
      "f620bf47e83d: Waiting\n",
      "5c0359201b8f: Waiting\n",
      "6c3e7df31590: Waiting\n",
      "5f70bf18a086: Layer already exists\n",
      "11028248fa9c: Pushed\n",
      "4674b64be78d: Pushed\n",
      "02428eed6535: Layer already exists\n",
      "4a0a5c128293: Layer already exists\n",
      "3e6a356c8e45: Layer already exists\n",
      "484aaa05a493: Layer already exists\n",
      "48786340ab74: Layer already exists\n",
      "5b0bdb8eec88: Layer already exists\n",
      "348f0dd546ad: Layer already exists\n",
      "b89286a316e3: Layer already exists\n",
      "87253ce52fc2: Layer already exists\n",
      "dc1df578e095: Layer already exists\n",
      "bfca245d883b: Pushed\n",
      "a976e35b0162: Layer already exists\n",
      "9020defa345e: Layer already exists\n",
      "2243997e691d: Layer already exists\n",
      "51e59867d98a: Layer already exists\n",
      "8b942a46ff73: Layer already exists\n",
      "2316d1d13f80: Layer already exists\n",
      "23aa9e3f79b2: Layer already exists\n",
      "1de5b0cf4a95: Layer already exists\n",
      "2b4ab9c66c33: Layer already exists\n",
      "4c4b5ef162c6: Layer already exists\n",
      "def14ac3e467: Layer already exists\n",
      "ab8967843163: Layer already exists\n",
      "46d81ba1b88f: Layer already exists\n",
      "cca198a3aa21: Layer already exists\n",
      "6e2c6cec7c79: Layer already exists\n",
      "1165bb2e119f: Layer already exists\n",
      "ef177fb935b3: Layer already exists\n",
      "5cb9ea7abb90: Layer already exists\n",
      "5f0f06d0dbe1: Layer already exists\n",
      "7623c51736a6: Layer already exists\n",
      "b07ea64c8933: Layer already exists\n",
      "9dbd6d766fae: Layer already exists\n",
      "8d78458ccbe2: Layer already exists\n",
      "f620bf47e83d: Layer already exists\n",
      "5c0359201b8f: Layer already exists\n",
      "6c3e7df31590: Layer already exists\n",
      "62b141942429: Pushed\n",
      "b03af6cdb18c: Pushed\n",
      "86517583b6e1: Pushed\n",
      "latest: digest: sha256:baa4d2dc53ac5a566291b91b207396e490e8dddd14567384125d2f4bdf320196 size: 9751\n"
     ]
    }
   ],
   "source": [
    "%%sh -s \"$region_name\" \"$role\" \"$bucket\" \"$account_id\" \"$inference_image\"\n",
    "region=$1\n",
    "account=$4\n",
    "inference_image=$5\n",
    "echo $region   $account\n",
    "aws ecr get-login-password --region $region | docker login --username AWS --password-stdin $account.dkr.ecr.$region.amazonaws.com.cn\n",
    "\n",
    "inference_fullname=$account.dkr.ecr.$region.amazonaws.com.cn/$inference_image:latest\n",
    "echo $inference_fullname\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${inference_image}\" --region $region || aws ecr create-repository --repository-name \"$inference_image\" --region $region\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${inference_image}\" --region ${region}\n",
    "    echo \"I am here created new ECR Repo $inference_image\"\n",
    "fi\n",
    "\n",
    "AWSchinaAccount=\"727897471807\"\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "docker login -u AWS -p $(aws ecr get-login-password --region $region) $AWSchinaAccount.dkr.ecr.$region.amazonaws.com.cn\n",
    "\n",
    "aws ecr set-repository-policy \\\n",
    "    --repository-name \"${inference_image}\" \\\n",
    "    --policy-text \"file://ecr-policy.json\" \\\n",
    "    --region ${region}\n",
    "\n",
    "#docker build -t ${inference_image} -f Dockerfile.inference . --build-arg REGION=$region\n",
    "docker build --no-cache -t ${inference_image} -f Dockerfile.inference . --build-arg REGION=$region\n",
    "\n",
    "docker tag ${inference_image} ${inference_fullname}\n",
    "\n",
    "docker push ${inference_fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c3fa0a",
   "metadata": {},
   "source": [
    "Upload the dummy file to S3 to meet the requirement of SageMaker Endpoint for model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67698259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n",
      "upload: ./model.tar.gz to s3://sagemaker-cn-north-1-415056049790/SD3-ComfyUI-fake/data/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data = \"s3://{0}/SD3-ComfyUI-fake/data/model.tar.gz\".format(bucket)\n",
    "!touch dummy\n",
    "!tar czvf model.tar.gz dummy\n",
    "!rm dummy\n",
    "!aws s3 cp model.tar.gz $model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928dcff9",
   "metadata": {},
   "source": [
    "## Deploy to SageMaker Asychronous Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bfa87d",
   "metadata": {},
   "source": [
    "Initialized the variables for URI of Docker Inference Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53195339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415056049790.dkr.ecr.cn-north-1.amazonaws.com.cn/sd3-compyui-notebook-7-12:latest\n"
     ]
    }
   ],
   "source": [
    "model_name = None\n",
    "image_uri = \"{0}.dkr.ecr.{1}.amazonaws.com.cn/{2}:latest\".format(\n",
    "    account_id, region_name, inference_image\n",
    ")\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111fce9c",
   "metadata": {},
   "source": [
    "Define the models configuration in order to download those models from one of source - HTTP, S3 and HuggingFace. Note: Here as an example the Lora model - 2bNierAutomataLora_v2b.safetensors and ControlNet model - control_sd15_canny.pth are going to be downloaded from Civitai and Huggingface directly once the SageMaker endpoint is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb54cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "huggingface_models = [\n",
    "    {\n",
    "    }\n",
    "]\n",
    "\n",
    "model_environment = {\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff86407",
   "metadata": {},
   "source": [
    "Define the model, instance type and instance initial count for SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    image_uri=image_uri,\n",
    "    env=model_environment,\n",
    "    predictor_cls=Predictor,\n",
    ")\n",
    "\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a41db6",
   "metadata": {},
   "source": [
    "Define the SageMaker Asychronous Inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=\"s3://{0}/{1}/asyncinvoke/out/\".format(bucket, \"sd3-comfyui\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640a1c8",
   "metadata": {},
   "source": [
    "Here we use asynchronous inference since asynchronous inference is more suitable for workloads with large payload sizes and long inference processing times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755b444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint sd3-compyui-notebook-7-12-2024-07-12-16-08-22-960: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_count\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_config\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/model.py:1721\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, inference_component_name, routing_config, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_explainer_enabled:\n",
      "\u001b[1;32m   1719\u001b[0m     explainer_config_dict \u001b[38;5;241m=\u001b[39m explainer_config\u001b[38;5;241m.\u001b[39m_to_request_dict()\n",
      "\u001b[0;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_from_production_variants\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduction_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mproduction_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_logging\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1731\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls:\n",
      "\u001b[1;32m   1734\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5711\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict, live_logging, vpc_config, enable_network_isolation, role)\u001b[0m\n",
      "\u001b[1;32m   5708\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating endpoint-config with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n",
      "\u001b[1;32m   5709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_options)\n",
      "\u001b[0;32m-> 5711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   5712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   5713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   5714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_tags\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   5715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   5716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   5717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:4569\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait, live_logging)\u001b[0m\n",
      "\u001b[1;32m   4566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_arn \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpointArn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;32m   4568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n",
      "\u001b[0;32m-> 4569\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint_name\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5354\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll, live_logging)\u001b[0m\n",
      "\u001b[1;32m   5348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n",
      "\u001b[1;32m   5349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n",
      "\u001b[1;32m   5350\u001b[0m             message\u001b[38;5;241m=\u001b[39mmessage,\n",
      "\u001b[1;32m   5351\u001b[0m             allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n",
      "\u001b[1;32m   5352\u001b[0m             actual_status\u001b[38;5;241m=\u001b[39mstatus,\n",
      "\u001b[1;32m   5353\u001b[0m         )\n",
      "\u001b[0;32m-> 5354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n",
      "\u001b[1;32m   5355\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n",
      "\u001b[1;32m   5356\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n",
      "\u001b[1;32m   5357\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n",
      "\u001b[1;32m   5358\u001b[0m     )\n",
      "\u001b[1;32m   5359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint sd3-compyui-notebook-7-12-2024-07-12-16-08-22-960: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=instance_count,\n",
    "    container_startup_health_check_timeout=900,\n",
    "    async_inference_config=async_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be6310",
   "metadata": {},
   "source": [
    "## Generate initial image using text prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"text-to-image\",\n",
    "    \"txt2img_payload\": {\n",
    "        \"prompt\": \"((Best quality)), ((masterpiece)), ((realistic)), (detailed), cute panda ((standing in a asian garden with cherry trees)) ((masterpiece)), absurdres, HDR\",\n",
    "        \"negative_prompt\": \"(bad quality)\",\n",
    "        \"seed\": 2816240246,\n",
    "        \"sampler_name\": \"Euler a\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"steps\": 20,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"width\": 512,\n",
    "        \"height\": 768,\n",
    "        \"alwayson_scripts\": {},\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89fc9c",
   "metadata": {},
   "source": [
    "Helper function for S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c071693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "\n",
    "s3_resource = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "def get_bucket_and_key(s3uri):\n",
    "    pos = s3uri.find(\"/\", 5)\n",
    "    bucket = s3uri[5:pos]\n",
    "    key = s3uri[pos + 1 :]\n",
    "    return bucket, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a726245",
   "metadata": {},
   "source": [
    "Wait until the asychronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae9d58",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921332a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    image_object = json.loads(body)[\"images\"][0]\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_object)))\n",
    "    image.show()\n",
    "    initial_image_filename = datetime.now().strftime(f\"%Y%m%d%H%M%S-{uuid.uuid4()}.png\")\n",
    "    image.save(initial_image_filename)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05421e0e",
   "metadata": {},
   "source": [
    "## Expand initial image using text prompt and ControlNet models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4f43a",
   "metadata": {},
   "source": [
    "ControlNet is a neural network structure to control diffusion models by adding extra conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cfc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    with io.BytesIO() as output_bytes:\n",
    "        if isinstance(image, dict):\n",
    "            image = image[\"image\"]\n",
    "        format = \"PNG\" if image.mode == \"RGBA\" else \"JPEG\"\n",
    "        image.save(output_bytes, format=format)\n",
    "        bytes_data = output_bytes.getvalue()\n",
    "\n",
    "    encoded_string = base64.b64encode(bytes_data)\n",
    "\n",
    "    base64_str = str(encoded_string, \"utf-8\")\n",
    "    mimetype = \"image/jpeg\" if format == \"JPEG\" else \"image/png\"\n",
    "    image_encoded_in_base64 = (\n",
    "        \"data:\" + (mimetype if mimetype is not None else \"\") + \";base64,\" + base64_str\n",
    "    )\n",
    "    return image_encoded_in_base64\n",
    "\n",
    "\n",
    "def decode_base64_to_image(encoding):\n",
    "    if encoding.startswith(\"data:image/\"):\n",
    "        encoding = encoding.split(\";\")[1].split(\",\")[1]\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(base64.b64decode(encoding)))\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb02b97",
   "metadata": {},
   "source": [
    "Define the payload for SageMaker inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b611cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "inputs = {\n",
    "    \"task\": \"image-to-image\",\n",
    "    \"img2img_payload\": {\n",
    "        \"prompt\": \"((Best quality)), ((masterpiece)), ((realistic)), (detailed), cute panda ((standing in a asian garden with cherry trees)) ((masterpiece)), absurdres, HDR\",\n",
    "        \"negative_prompt\": \"(bad quality)\",\n",
    "        \"init_images\": [encode_image_to_base64(image)],\n",
    "        \"mask\": None,\n",
    "        \"steps\": 20,\n",
    "        \"sampler_name\": \"Euler a\",\n",
    "        \"batch_size\": 1,\n",
    "        \"n_iter\": 1,\n",
    "        \"cfg_scale\": 7,\n",
    "        \"denoising_strength\": 0.8,\n",
    "        \"seed\": 2866147124,\n",
    "        \"height\": 768,\n",
    "        \"width\": 1280,\n",
    "        \"resize_mode\": 0,\n",
    "        \"include_init_images\": False,\n",
    "        \"alwayson_scripts\": {\n",
    "            \"controlnet\": {\n",
    "                \"args\": [\n",
    "                    {\n",
    "                        \"enabled\": True,\n",
    "                        \"module\": \"inpaint_only+lama\",\n",
    "                        \"model\": \"control_v11p_sd15_inpaint [ebff9138]\",\n",
    "                        \"image\": encode_image_to_base64(image),\n",
    "                        \"resize_mode\": \"Resize and Fill\",\n",
    "                        \"low_vram\": False,\n",
    "                        \"weight\": 1,\n",
    "                        \"guidance_start\": 0,\n",
    "                        \"guidance_end\": 1,\n",
    "                        \"pixel_perfect\": False,\n",
    "                        \"control_mode\": \"ControlNet is more important\",\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "prediction = predictor.predict_async(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147d5d51",
   "metadata": {},
   "source": [
    "Wait until the asynchronous inference is done in case we use asynchronous inference for image generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.waiter_config import WaiterConfig\n",
    "\n",
    "print(f\"Response object: {prediction}\")\n",
    "print(f\"Response output path: {prediction.output_path}\")\n",
    "print(\"Start Polling to get response:\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "config = WaiterConfig(\n",
    "    max_attempts=100, delay=10  #  number of attempts  #  time in seconds to wait between attempts\n",
    ")\n",
    "\n",
    "prediction.get_result(config)\n",
    "\n",
    "print(f\"Time taken: {time.time() - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4099a67",
   "metadata": {},
   "source": [
    "Process the generated images from asynchronous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ab136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from PIL import Image\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    output_bucket, output_key = get_bucket_and_key(prediction.output_path)\n",
    "    output_obj = s3_resource.Object(output_bucket, output_key)\n",
    "    body = output_obj.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    image_object = json.loads(body)[\"images\"][0]\n",
    "    image2 = Image.open(BytesIO(base64.b64decode(image_object)))\n",
    "    image2.show()\n",
    "    image2.save(datetime.now().strftime(f\"%Y%m%d%H%M%S-{uuid.uuid4()}.png\"))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af037a96",
   "metadata": {},
   "source": [
    "## Run generative fill application built with Gradio framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/xieyongliang/generative-fill-webui.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./generative-fill-webui && export sagemaker_endpoint=$endpoint_name && pip install -r requirements.txt && python ui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6342e74",
   "metadata": {},
   "source": [
    "## [Optional] Create auto-scaling group for SageMaker endpoint in case you want to scale it based on specific metrics automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5616f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoscaling_group_for_sagemaker_endpoint(\n",
    "    endpoint_name, min_capcity=1, max_capcity=2, target_value=5\n",
    "):\n",
    "    # application-autoscaling client\n",
    "    asg_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "    # This is the format in which application autoscaling references the endpoint\n",
    "    resource_id = f\"endpoint/{endpoint_name}/variant/AllTraffic\"\n",
    "\n",
    "    # Configure Autoscaling on asynchronous endpoint down to zero instances\n",
    "    response = asg_client.register_scalable_target(\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        MinCapacity=min_capcity,\n",
    "        MaxCapacity=max_capcity,\n",
    "    )\n",
    "\n",
    "    response = asg_client.put_scaling_policy(\n",
    "        PolicyName=f\"Request-ScalingPolicy-{endpoint_name}\",\n",
    "        ServiceNamespace=\"sagemaker\",\n",
    "        ResourceId=resource_id,\n",
    "        ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "        PolicyType=\"TargetTrackingScaling\",\n",
    "        TargetTrackingScalingPolicyConfiguration={\n",
    "            \"TargetValue\": target_value,\n",
    "            \"CustomizedMetricSpecification\": {\n",
    "                \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n",
    "                \"Namespace\": \"AWS/SageMaker\",\n",
    "                \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": endpoint_name}],\n",
    "                \"Statistic\": \"Average\",\n",
    "            },\n",
    "            \"ScaleInCooldown\": 600,  # duration until scale in begins (down to zero)\n",
    "            \"ScaleOutCooldown\": 300,  # duration between scale out attempts\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "create_autoscaling_group_for_sagemaker_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ab1c9",
   "metadata": {},
   "source": [
    "## Resource cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eabc2b",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/inference|generativeai|llm-workshop|lab12-hosting-controlnet-models-on-sagemaker|stable-diffusion-webui-async-inference-sagemaker-notebook.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
